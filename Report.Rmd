---
title: "Report"
author: "Soon Woo Hong"
date: "Friday, February 12, 2016"
output: html_document
---

## 1. Introduction

[Link to the github repo](https://github.com/53wjdejf/Coursera-Data-Science)

#### About the data
Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

[Read more (link)](http://groupware.les.inf.puc-rio.br/har#ixzz401egwpTt)

## 2. Data preprocessing  

### 2.1. Preparing
```{r, cache = T, echo=T, warning=FALSE}
library(corrplot)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(ggplot2)
```

### 2.2. Download the data
```{r, cache = T, echo=T}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data8/pml-training.csv"
testFile  <- "./data8/pml-testing.csv"
```

The files will be downloaded in the folder named "data8"
```{r, cache = T, echo=T}
if (!file.exists("./data8")) {
  dir.create("./data8")
}

if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
```  

### 2.3. Read the Data
After downloading the data, we can read the two unprocessed files (train1/test1)
```{r, cache = T, echo=T}
train1 <- read.csv(trainFile)
test1 <- read.csv(testFile)
data.frame(dim(train1), dim(test1))
```

### 2.4. Clean the data

In advance, we can count the missing values to look for need to cleaning the data.

Number of NA values are...`r sum(is.na(train1))`

First, we can remove columns that contain NA missing values or non-numeric values.
```{r, cache = T, echo=T}
train2 <- train1[, colSums(is.na(train1)) == 0]
train2 <- train2[ ,sapply(train2, is.numeric)] 

test2 <- test1[, colSums(is.na(test1)) == 0]
test2 <- test2[ ,sapply(test2, is.numeric)] 
```  

Next, we get rid of some columns that isn't thought to be much related to the accelerometer measurements.

(1. Greping undefined column, date data, and window. 2. Adding the "classe" variable that has been removed)
```{r, cache = T, echo=T}
train3 <- train2[, !(grepl("^X|timestamp|window", names(train2)))]
train3$classe <- train1$classe
test3 <- test2[, !(grepl("^X|timestamp|window", names(test2)))]
```
Now, train3/test3 are the completely processed data.

#### figure 1 Correlation matrix
```{r, cache=T, echo=T}
corr <- cor(train3[, -53])
corrplot(corr, method="color", diag=FALSE, tl.cex=0.6, tl.col="black")
```

All 53 variables except 'classe' are plotted. It shows quite a lot correlated covariates.

##3. Machine learning

###3.1. Model selection

Among various machine learning methods, we fit a model using **Random Forest** algorithm since it has high accuracy, and good for many correlated covariates. We will also do the cross validation.

> Tree vs. Forest

> A single tree may over fit to the training data.
> Instead, train multiple trees and combine their predictions.
> Each tree can differ in both training data and node tests.
> Achieve this by injecting randomness into training algorithm.

###3.2. Create data partition

```{r, cache = T, echo=T}
set.seed(1111)
inTrain <- createDataPartition(train3$classe, p=0.70, list=F)
training <- train3[inTrain, ]
testing <- train3[-inTrain, ]
```

###3.3. Data Modeling

After training(random forest & 4-fold cross validation) and predict, we evaluate the model on the test set
```{r, cache = T, echo=T}
set.seed(2222)
trControl <- trainControl(method="cv", 4)
model <- train(classe ~ ., data=training, method="rf", trControl=trControl, ntree=100)
predict <- predict(model, testing)
```

#### figure 2 Decision Tree
```{r, cache = T, echo=T}
tree <- rpart(classe ~ ., data=train3, method="class")
prp(tree, type=0, tweak=1.4)
```

###3.4. Model evaluation

By using 'table'(or confusionMatrix), 'postResample', we can see the overall accuracy.
```{r, cache = T, echo=T}
table(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
resultName <- c("estimated accuracy of the model", "estimated out of sample error")
resultValue <- c(as.numeric(accuracy[1]), 1 - as.numeric(accuracy[1]))
data.frame(resultValue, row.names=resultName)
```
So, the estimated out of sample error is 0.58%.

And we can evaluate the model by visualization

#### figure 3 Correlation matrix
```{r, cache = T, echo=T}
par(mfrow=c(1,2))
corrplot(prop.table(table(testing$classe, predict)), method="pie", title="Linear")
corrplot(prop.table(log(table(testing$classe, predict)+1)), method="pie", title="Logarithmic")
```

### 3.5. Predicting for test data set
Now, we apply the model to the testing data set.
```{r, cache = T, echo=T}
result <- predict(model, test3)
result
```  
